{"title":"Tidy questionnaire data: demo","markdown":{"yaml":{"title":"Tidy questionnaire data: demo","format":"html"},"headingText":"About","containsRefs":false,"markdown":"\n\n```{r}\n#| message: false\nlibrary(tidyverse)\n```\n\n\nThe goal of this notebook is to compare various data analysis programming approaches to scoring questionnaire data--which is perhaps the most common operation to perform on questionnaire data.\n\nOne common approach is to have the data organized into a one-agent-per-row format so that responses to various questions are encoded in separate columns and by doing operations on those columns, new score columns can be computed.\n\nWhen the data is organized into a one-response-per-row format (which we call the tidy questionnaire format), then several strategies are possible and we will explore maybe some of them.\n\n## Sample dataset\n\n```{r}\n#| message: false\nbfi2 <- read_csv(\"data/x_bfi2.csv\")\npsqi <- read_csv(\"data/psqi.csv\")\n```\n\nHere we will use a real, albeit small data set, as our goal is only to explore coding strategies that are nevertheless meant to apply to real use cases. This dataset contains data from 8 participants who completed at least one of two standard questionnaires, either once or twice. For simplicity, this dataset is offered as two distinct tabular csv files, one per questionnaire.\n\nThe first questionnaire in this dataset is a slightly modified version of the bfi-2 personality test which contains 60 questions. We picked this questionnaire for this example because it is well-known and widely used, contains many items and can be used to compute a large number of scores and subscores (called \"domain scales\" and \"fact scales\"). This dataset contains data for only three participants: two of these completed the questionnaire twice, and of them completed it only once.\n\nThe second questionnaire in this dataset is the \"Pittsburgh Sleep Quality Index (PSQI)\". We chose this questionnaire because it uses a wide range of responses types (e.g., time of day, number of minutes, hours per night, ordered categories representing a frequency, open text responses, ratings of quality) and uses more complex scoring rules--this questionnaire may therefore pose additional challenges for data organization and analysis. This dataset contains data from 5 participants who all completed that questionnaire twice. Furthermore, one of these participants (agent_id \"030\") is also included in the bfi-2 data.\n\nFor each question we recorded what response option participants chose, how long it took them to select that option once the question was displayed (each question was displayed one by one on the screen), and how long it took them to validate their response by clicking on the \"Next\" button (participants could change their responses, while a given question was displayed, but once they clicked \"Next\", they were presented with the next question and could not navigate back to earlier questions.) These are just a subset of information that could be collected per response, which is nevertheless more than what seems to be typically collected in questionnaire data.\n\n\n\n## Data formats: tidy/long vs untidy/wide\n\n\nWe stored the two data tables in the tidy questionnaire data format and will now create a version of these two data files that follows the \"one-person-per-row\" (aka \"wide\") format. Furthermore, we will combine both pairs of files to form a combined tidy and a combined wide table respectively. This is to illustrate in particular how data from multiple questionnaires may be combined and how sparsity in each questionnaire data affects the size of the resulting combined tables.\n\n\n\n```{r}\n# step 1: create wide data versions of the two tables\nbfi2_wide <- bfi2 |> pivot_wider(id_cols = c(agent_id, instrument_id), \n                           names_from = c(stimulus_id, iteration), \n                           names_glue = \"{stimulus_id}_{.value}_i{iteration}\",\n                           values_from = c(trial_index,\n                                           stimulus_type,\n                                           stimulus_description, \n                                           response_option_index, \n                                           response_description, \n                                           response_numeric, \n                                           response_time, \n                                           response_validation_time))\n\npsqi_wide <- psqi |> pivot_wider(id_cols = c(agent_id, instrument_id), \n                           names_from = c(stimulus_id, iteration), \n                           names_glue = \"{stimulus_id}_{.value}_i{iteration}\",\n                          values_from = c(trial_index,\n                                           stimulus_type,\n                                           stimulus_description, \n                                           response_option_index, \n                                           response_description, \n                                           response_numeric, \n                                           response_time, \n                                           response_validation_time))\n\n# step 2: create a table that combines data from the two questionnaires\nD_tidy <- rbind(bfi2, psqi)\n\nD_wide <- full_join(bfi2_wide, psqi_wide, by = \"agent_id\")\n\n\n# step 3: save the generated tables as csv files\nwrite.csv(bfi2_wide, file = 'data/x_bfi2_wide.csv')\nwrite.csv(psqi_wide, file = 'data/psqi_wide.csv')\nwrite.csv(D_tidy, file = 'data/D_tidy.csv')\nwrite.csv(D_wide, file = 'data/D_wide.csv')\n\n```\n\n```{r}\n#| echo: false\n\n# Create a data frame for the table\ntable_data <- data.frame(\n  dataset = c(\"bfi2\", \"psqi\", \"D_tidy (combined)\", \"\", \"bfi2_wide\", \"psqi_wide\", \"D_wide (combined)\"),\n  rows = c(nrow(bfi2), nrow(psqi), nrow(D_tidy), NA, nrow(bfi2_wide), nrow(psqi_wide), nrow(D_wide)),\n  columns = c(ncol(bfi2), ncol(psqi), ncol(D_tidy), NA, ncol(bfi2_wide), ncol(psqi_wide), ncol(D_wide)),\n  rows_x_cols = c(prod(dim(bfi2)), prod(dim(psqi)), prod(dim(D_tidy)), NA, prod(dim(bfi2_wide)), prod(dim(psqi_wide)), prod(dim(D_wide))),\n  NAs = c(sum(is.na(bfi2)), sum(is.na(psqi)), sum(is.na(D_tidy)), NA, sum(is.na(bfi2_wide)), sum(is.na(psqi_wide)), sum(is.na(D_wide))),\n  csv_size = c(\"31.5 KB\", \"27.5 KB\", \"66.6 KB\", \"\", \"59.6 KB\", \"36.2 KB\", \"109.1 KB\")\n)\n\nknitr::kable(table_data, col.names = c(\"dataset\", \"rows\", \"columns\", \"rows x cols\", \"NAs\", \"csv size\"),\n             caption = \"Dimensions and NA counts for each dataset, separately and combined, under the tidy and the wide tabular formats.\")\n```\n\n\n\n\nThere are several important points to note in the table above. The tidy data tables all have the same small number of columns; their number of rows will vary depending on the amount of data collected. Conversely, their wide-formatted counterparts have a number of rows and columns that both depend on the specific dataset and study design (e.g., more repetitions of the same questions would lead to more columns). Thus the shape of the tables when they are wide is less predictable. Furthermore, because columns represent the attributes of an observation, the wide format is much more difficult to process. For example, there are 978 columns in the wide version of the bfi2 data but only 12 in its tidy version. When looking at the number of missing values it is clear to see that in some cases (when data is sparse), the number of missing values increases substantially when transforming the data from tidy to wide (for bfi2, that number increased from 15 to 503). Another important observation is that when combining tidy questionnaire tables, the resulting table is easily predictable: the numbers of rows and the number of NAs are simply added, while the number (and meaning) of the columns remain the same. In contrast, when combining wide data tables, the resulting table is unpredictable without knowledge about the content of the data. Note also the large increase in NAs for this combined table (5121) compared to the combined tidy data (115).\n \nWe also wanted to assess whether these data formats affect the size of the data. One simple but somewhat naive way of assessing size is to count the number of cells in each table. While this may in principle serve as a proxy, it is not that straightforward because the data in each cell may require more or less memory space depending for instance on how it is encoded (e.g., a boolean vs a string). The strategy we chose here was to save the various data tables as csv files and assess the size of those files. As can be seen in the table, the wide formats in our example are systematically larger than their tidy counterparts.    \n\n\n\n\n## Scoring questionnaires\n\nThe next step will be to score each of the questionnaires, using the tidy and wide data formats and compare their advantages and disadvantages. In addition to computing those scores we will also compute the median response time to answer the corresponding questions. While this is not classically done, the idea of including it here is to assess how computing additional metrics on more than one response attribute would affect the complexity of the code.\n\n\n### BFI-2\n\n#### The wide data format\n\nWe'll start with the wide data format as this is the most common and the \"approach\" to scoring such data appears at least conceptually the most straightforward: because the data is already organized in an one-row-per-person format, scoring a questionnaire simply implies doing specific operations on a subset of the columns of that table.\n\n\nLet's start with a simple example: computing the *anxiety* score from the bfi2 data. According to the [documentation](https://www.colby.edu/academics/departments-and-programs/psychology/research-opportunities/personality-lab/the-bfi-2/), this requires using the responses from the items  Anxiety: 4R, 19, 34, 49R (where R indicates items that need to be reverse coded).\n\nSo our first challenge is to figure out how to find the responses to those times in our dataset. \n\n\n```{r}\n# custom function to convert response option index into the response score as defined in documentation\ncompute_agreement_rate_vector <- function(x, level_count = 7, reverse = FALSE){\n  rate <- (x-1)/(level_count-1)  \n  if (reverse){\n    rate <- 1-rate\n  }\n  rate\n}\n\n\n\n# custom function to compute the anxiety score\ncompute_anxiety_score <- function(df, iteration){\n  # - Anxiety: 4R, 19, 34, 49R\n  iteration_text <- paste0('_i', iteration)\n (compute_agreement_rate_vector(df[[paste0('bfi-2_q_4_response_option_index', iteration_text)]], reverse = TRUE) +\n  compute_agreement_rate_vector(df[[paste0('bfi-2_q_19_response_option_index', iteration_text)]], reverse = FALSE) +\n  compute_agreement_rate_vector(df[[paste0('bfi-2_q_34_response_option_index', iteration_text)]], reverse = FALSE) +\n  compute_agreement_rate_vector(df[[paste0('bfi-2_q_49_response_option_index', iteration_text)]], reverse = TRUE)) / 4\n}\n\n# computing the anxiety score and adding as a new column to the data\nD_wide$anxiety_score_i1 <- compute_anxiety_score(D_wide, iteration = 1)\nD_wide$anxiety_score_i2 <- compute_anxiety_score(D_wide, iteration = 2)\n\n\n# we can do something similar to compute the average response times\ncompute_anxiety_response_times <- function(df, iteration){\n  iteration_text <- paste0('_i', iteration)\n  (df[[paste0('bfi-2_q_4_response_time', iteration_text)]] +\n  df[[paste0('bfi-2_q_19_response_time', iteration_text)]] +\n  df[[paste0('bfi-2_q_34_response_time', iteration_text)]] +\n  df[[paste0('bfi-2_q_49_response_time', iteration_text)]]) / 4\n}\n\nD_wide$anxiety_response_times_i1 <- compute_anxiety_response_times(D_wide, iteration = 1)\nD_wide$anxiety_response_times_i2 <- compute_anxiety_response_times(D_wide, iteration = 2)\n\n```\n\n```{r}\nD_wide[c('agent_id', 'anxiety_score_i1', 'anxiety_score_i2', 'anxiety_response_times_i1', 'anxiety_response_times_i2')]\n```\n\n\nThere are several points we want to highlight about the code above. Firstly, this type of code tends to be quite verbose. We wrote functions here to aim to make that code compact; in practice it is rather common to not see any such functions but instead see long assignment statements. \n\nSecondly, the code above is strongly tied, not only to information about the questionnaire (e.g., which items to pick)--which is unavoidable--, it is also strongly tied to the specific way in which the column names have been arbitrarily constructed. If for some reason we change how column names are constructed, we could have to replace all of the code above. Furthermore, if the study had not involved repetitions, the naming would have been different and thus we would have again to change the code. \n\nThird, as in our example there are (up to) 2 repetitions of this questionnaire, we have to manually run the scoring code on each value of those iterations. Again, if there were a different number of iterations or different  intentions to group data (e.g., completing surveys in morning vs evening), we would again have to change the code above.\n\nFinally, when computing multiple aggregates on a particular response (in our example, how long they took to respond to those questions), we can see that it requires pretty much writing an independent chunk of code (the code for the anxiety response time and the code for anxiety scores are run independently from each other). This means that there are redundancies and the potential for mistakes. For example, the selection of items is the same in both cases (i.e., 4R, 19, 34, 49R), but this selection is specified in two different locations (both as part of the column names to be selected). As these are entered manually, and because for a given study there could potentially be a large number of such duplicated lists (e.g., there are 20 scores that one can compute out of this bfi2 questionnaire) which makes it hard to not make mistakes and to check that no mistakes were made. The above code takes about 25 lines to compute two metrics for one dimension; if we extrapolate, scoring the bfi2 questionnaire in this way would require 500 lines of code. \n\n\n> The names of the aggregated values need to be specified by the data analyst. For example, here we chose \"anxiety_score_i1\". This is again an arbitrary choice (we could have picked instead \"score_bfi_anx_1\", \"anxiety_r1_bfi2\", or something else). This custom naming of the outputs requires extra work, is specific to the dataset (if there were more repetitions, we would need additional assignment statements); it will also cause the subsequent code to be tailor made to those specific column names.\n\n\nIt is of course possible to develop more custom code (i.e., more functions) to make the data analysis code more compact, less redundant and less error prone. But that code would require extra work, it would likely be highly specific to the way the column names were constructed for this particular dataset, and in practice, this does not seem to be what data analysts do. \n\n\n#### The tidy data format\n\nWe will now do the same type of analysis starting with the tidy data format.\n\n\n\n```{r}\n\nscore_bfi2_anxiety <- function(df){\n\n    df |> \n    # \"select\" the relevant items for this scale\n    filter(stimulus_id %in% paste0(\"bfi-2_q_\", c(4, 19, 34, 49))) |> \n    # recode responses into 0-1 \n    mutate(response_score = ifelse(stimulus_id %in% paste0(\"bfi-2_q_\", c(4, 49)), \n                                   compute_agreement_rate_vector(response_option_index, reverse = TRUE), # reverse score for selected items \n                                   compute_agreement_rate_vector(response_option_index, reverse = FALSE))) |> \n    # compute score for this scale\n    summarize(\n      dimension = \"bfi2_extraversion\",\n      score = mean(response_score), \n      response_time_mean = mean(response_time),\n      .groups = \"drop\")\n  \n}\n\n\n# compute the scores for our dataset\nbfi2_anxiety <- D_tidy |> \n  group_by(agent_id, iteration) |> \n  score_bfi2_anxiety()\n\nknitr::kable(bfi2_anxiety)\n```\n\nThere are several points worth noting about the code above. Firstly, the code in `score_bfi2_anxiety()` only contains information about the IDs of the items that need to be used and how they are to be used. It does not contain any information related to the specifics of the study or data analysis intention. For instance, there is no notion of \"repetition\" in this code. Second, the selection of relevant items is done only once with the filter statement; this makes the code more compact and less error prone.  Thirdly, the way that aggregates are computed on the data--which is done via the `summarize()`--makes it very easy to add additional metrics. For instance, if one wanted to also compute the minimum, maximum of and standard deviation of the response times, it would only require one additional statement per metric within the summarise function (e.g., `response_time_min = min(response_time)`; this is in stark contrast with how we analyzed the wide data.\n\nForth, if we look at how those functions are being applied to the data, we can see that by using the `group_by()` function (which is part of the dplyr package, included in the tidyverse) we can apply the scoring functions for any type of subset of our data. Here we specify that we want to have separate scoring for each agent and for each iteration. We don't need to know or specify in advance how many iterations are in the dataset. The number of iterations does not impact the amount of code one needs to write. This code is also easy to update in the future; if there was a \"time_of_day\" column, that column could be used to compute different scores for whatever levels that variable has by simply changing the contents of that group_by() function. Importantly, this coding approach cleanly separates the scoring function which is tied only to the questionnaire used from the specific study design and data analysis strategies (which in our example is embedded in the group_by() function call).\n\n\nIt is also important to note that the output of the scoring \"anxiety\" following this approach is again a tidy table where no extra effort was required to name things. The shape of this table will depend on the specific analysis that was computed (e.g., if there are more iterations, there will be more rows), but the columns of that table will reflect the various metrics computed in the summary call.\n\nOf course at some point one may want to display the table as a one-row-per-person table; this can be done quite easily. \n\n\n#### Scoring the bfi2 questionnaire as a whole\n\nAs stated earlier we won't use the strategy we employed for the wide data to score all of the dimensions as this would take us quite some time to do and would not be very interesting. But doing this exercise would certainly allow the reader to experience how painful that could be.\n\nHere we will only use the tidy data as a starting point. We will abstract the code above a bit more to show how compact questionnaire data analysis may be.\n\n\n\n```{r}\n# function to \"recode\" response values\ncompute_agreement_rate <- function(df, col = \"response_option_index\", level_count = 7, reverse = FALSE){\n  rate <- (df[[col]] - 1) / (level_count - 1)\n  if (reverse){\n    rate <- 1 - rate\n  }\n  rate\n}\n\n\n\n# function takes as input a data frame (df) and a list containing the parameters of a specific scale and outputs the resulting scores and response times\n# recode and aggregate\nscore_questionnaire <- function(df, scoring_params){\n  \n  # if reverse_ids is not defined, copy stimulus_ids\n  if (all(is.na(scoring_params$reverse_ids))){\n    scoring_params$reverse_ids <- \"__none__\"\n  }\n  \n  df |> \n    filter(stimulus_id %in% scoring_params$stimulus_ids) |> \n    mutate(response_score = ifelse(stimulus_id %in% scoring_params$reverse_ids, \n                                   scoring_params$recode_func(pick(everything()), reverse = TRUE), \n                                   scoring_params$recode_func(pick(everything()), reverse = FALSE))) |> \n    summarize(dimension = scoring_params$dimension,\n              score = mean(response_score, na.rm = TRUE), \n              response_time = mean(response_time, na.rm = TRUE), \n              n = n(),\n              na_n = sum(is.na(response_time)),\n              .groups = \"drop\"\n              ) \n}\n\n\n```\n \nThe code above is quite generic and applies to the common case where response option indices are converted to numbers using a particular set of rules and then aggregated. Because this code is generic and could apply to a wide range of questionnaires, it could be part of a package and reused broadly, preventing the need to write custom code.\n\nWe wrote the code in a way that the `score_questionnaire()` takes as input the questionnaire data and a list of parameters that specify how to score a particular dimension. This type of code that separates the specifics of a score (tied to a particular instrument) from the mechanics of computing the score is preferable over hard coding the specifics in the analysis code directly (as we did earlier) as it makes it easier to review if the specification is correct or not. \n\n\nTo compute a specific score, we will then need to do the following:\n\n\n```{r}\n# we can now encode the scoring rules for the questionnaire in a compact way:\nbfi2_extraversion <- list(\n  dimension = \"bfi2_extraversion\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(11, 16, 26, 31, 36, 51))\n)\n\n\n\n# and use the generic code to compute the results for that dimension:\nD_tidy |> \n  group_by(agent_id, iteration) |> \n  score_questionnaire(bfi2_extraversion) |> \n  knitr::kable()\n\n\n```\n\nTo compute all of the 20 scores from the bfi2 questionnaires, we first need to specify the parameters for each score. This can be done all in one, easy to review, place:\n\n```{r}\n# Storing all the scoring rules for the bfi-2 questionnaire in lists:\n\n## Extraversion: 1, 6, 11R, 16R, 21, 26R, 31R, 36R, 41, 46, 51R, 56\nbfi2_extraversion <- list(\n  dimension = \"bfi2_extraversion\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(11, 16, 26, 31, 36, 51))\n)\n\n## Agreeableness: 2, 7, 12R, 17R, 22R, 27, 32, 37R, 42R, 47R, 52, 57\nbfi2_agreeableness <- list(\n  dimension = \"bfi2_agreeableness\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(2, 7, 12, 17, 22, 27, 32, 37, 42, 47, 52, 57)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(12, 17, 22, 37, 42, 47))\n)\n\n## Conscientiousness: 3R, 8R, 13, 18, 23R, 28R, 33, 38, 43, 48R, 53, 58R\nbfi2_conscientiousness <- list(\n  dimension = \"bfi2_conscientiousness\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(3, 8, 13, 18, 23, 28, 33, 38, 43, 48, 53, 58)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(3, 8, 23, 28, 48, 58))\n)\n\n## Negative Emotionality: 4R, 9R, 14, 19, 24R, 29R, 34, 39, 44R, 49R, 54, 59\nbfi2_negative <- list(\n  dimension = \"bfi2_negative\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(4, 9, 14, 19, 24, 29, 34, 39, 44, 49, 54, 59)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(4, 9, 24, 29, 44, 49))\n)\n\n## Open-Mindedness: 5R, 10, 15, 20, 25R, 30R, 35, 40, 45R, 50R, 55R, 60\nbfi2_open <- list(\n  dimension = \"bfi2_open\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(5, 25, 30, 45, 50, 55))\n)\n\n## Sociability: 1, 16R, 31R, 46\nbfi2_sociability <- list(\n  dimension = \"bfi2_sociability\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(1, 16, 31, 46)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(16, 31))\n)\n\n## Assertiveness: 6, 21, 36R, 51R\nbfi2_assertiveness <- list(\n  dimension = \"bfi2_assertiveness\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(6, 21, 36, 51)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(36, 51))\n)\n\n## Energy Level: 11R, 26R, 41, 56\nbfi2_energy <- list(\n  dimension = \"bfi2_energy\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(11, 26, 41, 56)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(11, 26))\n)\n\n## Compassion: 2, 17R, 32, 47R\nbfi2_compassion <- list(\n  dimension = \"bfi2_compassion\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(2, 17, 32, 47)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(17, 47))\n)\n\n## Respectfulness: 7, 22R, 37R, 52\nbfi2_respectfulness <- list(\n  dimension = \"bfi2_respectfulness\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(7, 22, 37, 52)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(22, 37))\n)\n\n## Trust: 12R, 27, 42R, 57\nbfi2_trust <- list(\n  dimension = \"bfi2_trust\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(12, 27, 42, 57)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(27, 57))\n)\n\n## Organization: 3R, 18, 33, 48R\nbfi2_organization <- list(\n  dimension = \"bfi2_organization\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(3, 18, 33, 48)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(3, 48))\n)\n\n## Productiveness: 8R, 23R, 38, 53\nbfi2_productiveness <- list(\n  dimension = \"bfi2_productiveness\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(8, 23, 38, 53)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(8, 23))\n)\n\n## Responsibility: 13, 28R, 43, 58R\nbfi2_responsibility <- list(\n  dimension = \"bfi2_responsibility\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(13, 28, 43, 58)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(28, 58))\n)\n\n## Anxiety: 4R, 19, 34, 49R\nbfi2_anxiety <- list(\n  dimension = \"bfi2_anxiety\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(4, 19, 34, 49)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(4, 49))\n)\n\n## Depression: 9R, 24R, 39, 54\nbfi2_depression <- list(\n  dimension = \"bfi2_depression\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(9, 24, 39, 54)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(9, 24))\n)\n\n## Emotional Volatility: 14, 29R, 44R, 59\nbfi2_volatility <- list(\n  dimension = \"bfi2_volatility\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(14, 29, 44, 59)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(29, 44))\n)\n\n## Intellectual Curiosity: 10, 25R, 40, 55R\nbfi2_curiosity <- list(\n  dimension = \"bfi2_curiosity\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(10, 25, 40, 55)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(25, 55))\n)\n\n## Aesthetic Sensitivity: 5R, 20, 35, 50R\nbfi2_aesthetic <- list(\n  dimension = \"bfi2_aesthetic\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(5, 20, 35, 50)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(5, 50))\n)\n\n## Creative Imagination: 15, 30R, 45R, 60\nbfi2_imagination <- list(\n  dimension = \"bfi2_imagination\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(15, 30, 45, 60)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(30, 45))\n)\n\n```\n\n\nNote that the above is a sort of documentation of how to score the bfi2 questionnaire; this content should be an integral part of the questionnaire (and questionnaire data collection system) itself rather than being manually entered as we did here.\n\nOnce we have defined the list of scores we want to compute on our data, we can create a list of those parameter lists: \n\n\n```{r}\n## We can group all of those scale parameter lists into an instrument specific list\nbfi2_params <- list(\n  # 5 domain scales:\n  bfi2_extraversion,\n  bfi2_agreeableness,\n  bfi2_conscientiousness,\n  bfi2_negative,\n  bfi2_open,\n  # 15 facets:\n  bfi2_sociability,\n  bfi2_assertiveness,\n  bfi2_energy,\n  bfi2_compassion,\n  bfi2_respectfulness,\n  bfi2_trust,\n  bfi2_organization,\n  bfi2_productiveness, \n  bfi2_responsibility,\n  bfi2_anxiety,\n  bfi2_depression,\n  bfi2_volatility,\n  bfi2_curiosity,\n  bfi2_aesthetic,\n  bfi2_imagination)\n\n```\n\n\nThe next step is then to execute the scoring code on each of them:\n\n\n```{r}\n# we use purrr instead of for loops\n# we also first create a wrapper to simplify code\nf <- function(df, param_list){\n  df |> \n      group_by(agent_id, iteration) |> \n      score_questionnaire(param_list)\n}\n\nbfi2_scores <- map_dfr(bfi2_params, ~ f(D_tidy, .x))\n```\n\n\nThus if we exclude the generic code and the specification of how to score the bfi2 questionnaire, the code to score the questionnaire only takes a handful of lines of code, which are the same irrespective of the number of scores to extract from the questionnaire or from the number of iterations that participants completed.\n\n\nSome people might want at this stage to have a table showing for each person their score on the various dimensions of the questionnaire. We could simply use pivot_wider() here to create a one-person-per-row table. However, it is unlikely that we would want to display all of the data in bfi2_scores. As an example, we will only display the scores (i.e., ignoring response_time, n and na_n) and average the scores across repetitions when there are multiple. \n\n```{r}\nbfi2_scores_wide <- bfi2_scores |> \n  # averaging scores across repetitions for each dimension\n  group_by(agent_id, dimension) |> \n  summarize(score = mean(score, na.rm=TRUE), .groups = \"drop\") |> \n  # reshaping the table\n  pivot_wider(id_cols = agent_id, names_from = dimension, values_from = score)\n\n```\n```{r}\nknitr::kable(bfi2_scores_wide)\n```\n\n\n\n\n### PSQI\n\nThe PSQI questionnaire is more challenging to score because it involves a larger variety of response formats and because the scoring procedure is a bit more involved.\n\nAlso for brevity we will only focus only on computing the score for \"Component 2: Sleep latency\" as it involves multiple steps.\n\n\n#### The wide data format\n\n```{r}\n# question 2: convert duration ranges into integer 0-3\n# question 5: convert choice into integer 0-3\n# sum previous two scores\n# convert the sum into integer 0 -3\n\n\n# score question 2:\nvalidate_psqi_question_2_input <- function(x){\n  if (!is.numeric(x)) {\n    stop(\"Input must be numeric\")\n  } else if (any(x < 0, na.rm = TRUE)){\n    stop(\"Input must be larger than 0\")\n  }\n  return(x)\n}\n\n# validate_psqi_question_2_input(c(1, 1, 2, NA))\n\n\n\nscore_psqi_question_2 <- function(x){\n  validate_psqi_question_2_input(x)\n  as.numeric(cut(x, breaks = c(0,15, 30, 60, 24*60))) - 1\n}\n\n\n\n\n# score question 5:\nvalidate_psqi_question_5_input <- function(x){\n  \n  q5_levels = c(\"not during the past month\", \"less than once a week\", \"once or twice a week\", \"three or more times a week\")\n  \n  if (is.factor(x)) { # if x is encoded as a factor variable\n    if (! all(levels(x) == q5_levels)){\n      stop(paste0(\"Input does not have the required levels: \\nInput levels: \", levels(x), \"\\nExpected levels: \", q5_levels))\n    }\n  } else if (!is.character(x)){\n    stop(\"Input must be either factor or string\")\n  } else {\n    # check inputs are \n    for (element in x){\n      if (is.na(element)) next\n      if (!element %in% q5_levels){\n        stop(paste0(\"Input contains unexpected values: \", element) )\n      }\n    }\n  }\n  return(x)\n}\n\n\n\nscore_psqi_question_5 <- function(x){\n  validate_psqi_question_5_input(x)\n  as.numeric(\n    factor(x, levels = c(\"not during the past month\", \"less than once a week\", \"once or twice a week\", \"three or more times a week\"))\n  )-1\n}\n\n\n\n\n\n# combine the subcomponent scores\nscore_sleep_latency_components <- function(x,y){\n  as.numeric(\n    cut(x + y, breaks = c(-1, 0, 2, 4, 6))\n  )-1\n}\n\n# wrapper to do all the previous steps in one function call\nscore_sleep_latency <- function(q2,q5){\n  x <- score_psqi_question_2(q2)\n  y <- score_psqi_question_5(q5)\n  score_sleep_latency_components(x,y)\n}\n```\n\nThe code above shows that one can write simple functions to process each question separately, a function to aggregate those results and a wrapper function to keep the data analysis code cleaner.  It is important to note here that this code expects very specific input values: in the first case a number of minutes (i.e., a positive number between 0 and 1440), in the second, one out of 4 possible response categories. In the above code we show how the data analysis code can make sure that the input is as expected (as opposed to relying on the data being correctly formatted). \n\nHaving created those functions, we can now analyze our specific dataset:\n\n```{r}\n# use the above code to compute the psqi sleep latency score for each iteration and append to data\nD_wide <- D_wide |> \n  mutate(psqi_latency_score_i1 = score_sleep_latency(\n                                      psqi_q_2_response_numeric_i1, \n                                      `frequency_trouble_sleep_because;psqi-past_q_6_response_description_i1`\n                                      ),\n         psqi_latency_score_i2 = score_sleep_latency(\n                                      psqi_q_2_response_numeric_i2, \n                                      `frequency_trouble_sleep_because;psqi-past_q_6_response_description_i2`\n                                      )\n         ) \n\n\n\n```\n\n\nThe above code is rather compact thanks to the use of functions. However, as in with the bfi2_wide example, we end up having to write code that is specific to our study: we need to compute the scores separately for each iteration, which leads to duplicated code and the potential to make mistakes (forgetting to change the i1 to i2 when copy-pasting code). \n\nThe second observation: we add new columns to the main table; we are now mixing in the table things that are data (responses to questions) and things that we compute using that data (the psqi sleep latency score). We could of course save the resulting columns in a separate table.\n\n```{r}\nD_wide |> \n  select(agent_id, psqi_latency_score_i1, psqi_latency_score_i2) |> \n  knitr::kable()\n\n```\n\n\n#### The tidy data format\n\nWe could use an approach similar to what we did for BFI-2: define a list of parameters to compute a specific score and a generic function to run the analysis of data. This would work for calculating the subscores, but then a second step would be required to compute the aggregate score from those two subscores. \n\nThe alternative is to create a function that takes as input a data frame and returns the scores\n\n\n\n```{r}\nscore_sleep_latency_components_df <- function(x){\n\n  if (length(x) != 2){\n    stop(\"Data does not have the expected number of items\")\n  } else {\n    score_sleep_latency_components(x[1], x[2])\n  }\n  \n}\n\n\n\nscore_psqi_latency <- function(df){\n  \n  # because rowwise will override any existing groups, we need to save and restore them when needed\n  group_vars <- dplyr::group_vars(df)\n  \n  df |> \n    filter(stimulus_id %in% c(\"psqi_q_2\", \"frequency_trouble_sleep_because;psqi-past_q_6\")) |> \n    # process each question separately\n    rowwise() |> \n    mutate(score_tmp = ifelse(stimulus_id==\"psqi_q_2\", \n                          score_psqi_question_2(response_numeric), \n                          NA)) |> \n    mutate(score_tmp = ifelse(stimulus_id==\"frequency_trouble_sleep_because;psqi-past_q_6\",\n                          score_psqi_question_5(response_description), \n                          score_tmp)) |> \n    ungroup() |> \n    group_by(across(all_of(group_vars))) |> \n    \n    # aggregate scores across all selected responses\n    summarize(dimension = \"psqi_latency\", \n              score = score_sleep_latency_components_df(score_tmp), \n              response_time = mean(response_time, na.rm = TRUE), \n              n = n(),\n              na_n = sum(is.na(response_time)),\n              .groups = \"drop\"\n              ) \n  \n}\n```\n\n\n\n```{r}\nD_tidy |> \n  group_by(agent_id, iteration) |> \n  score_psqi_latency()\n\n```\n\n\nThe code in this case is quite a bit more complex; the main advantages are however that a) we can compute more metrics on the selected items without much effort (e.g., response_time) compared to the strategy we used on the wide data format and b) we can have studies that involve any number of iterations (or other types of grouping variables) and reuse the exact same code; in contrast, the code used on the wide data format is strongly tied to the specifics of the study, be it through the study parameters encoded in the column names or the number of steps required in the analysis.\n\n\n## Conclusion\n\nThis notebook presents a more realistic, although still simplified, example of the analysis of questionnaire data using the wide and tidy data formats respectively. Overall, the tidy data format seems preferable for several reasons. However, we also note that in some cases handling the tidy data format may require code that is more complex than the wide data format. \n\n\n","srcMarkdownNoYaml":"\n\n```{r}\n#| message: false\nlibrary(tidyverse)\n```\n\n## About\n\nThe goal of this notebook is to compare various data analysis programming approaches to scoring questionnaire data--which is perhaps the most common operation to perform on questionnaire data.\n\nOne common approach is to have the data organized into a one-agent-per-row format so that responses to various questions are encoded in separate columns and by doing operations on those columns, new score columns can be computed.\n\nWhen the data is organized into a one-response-per-row format (which we call the tidy questionnaire format), then several strategies are possible and we will explore maybe some of them.\n\n## Sample dataset\n\n```{r}\n#| message: false\nbfi2 <- read_csv(\"data/x_bfi2.csv\")\npsqi <- read_csv(\"data/psqi.csv\")\n```\n\nHere we will use a real, albeit small data set, as our goal is only to explore coding strategies that are nevertheless meant to apply to real use cases. This dataset contains data from 8 participants who completed at least one of two standard questionnaires, either once or twice. For simplicity, this dataset is offered as two distinct tabular csv files, one per questionnaire.\n\nThe first questionnaire in this dataset is a slightly modified version of the bfi-2 personality test which contains 60 questions. We picked this questionnaire for this example because it is well-known and widely used, contains many items and can be used to compute a large number of scores and subscores (called \"domain scales\" and \"fact scales\"). This dataset contains data for only three participants: two of these completed the questionnaire twice, and of them completed it only once.\n\nThe second questionnaire in this dataset is the \"Pittsburgh Sleep Quality Index (PSQI)\". We chose this questionnaire because it uses a wide range of responses types (e.g., time of day, number of minutes, hours per night, ordered categories representing a frequency, open text responses, ratings of quality) and uses more complex scoring rules--this questionnaire may therefore pose additional challenges for data organization and analysis. This dataset contains data from 5 participants who all completed that questionnaire twice. Furthermore, one of these participants (agent_id \"030\") is also included in the bfi-2 data.\n\nFor each question we recorded what response option participants chose, how long it took them to select that option once the question was displayed (each question was displayed one by one on the screen), and how long it took them to validate their response by clicking on the \"Next\" button (participants could change their responses, while a given question was displayed, but once they clicked \"Next\", they were presented with the next question and could not navigate back to earlier questions.) These are just a subset of information that could be collected per response, which is nevertheless more than what seems to be typically collected in questionnaire data.\n\n\n\n## Data formats: tidy/long vs untidy/wide\n\n\nWe stored the two data tables in the tidy questionnaire data format and will now create a version of these two data files that follows the \"one-person-per-row\" (aka \"wide\") format. Furthermore, we will combine both pairs of files to form a combined tidy and a combined wide table respectively. This is to illustrate in particular how data from multiple questionnaires may be combined and how sparsity in each questionnaire data affects the size of the resulting combined tables.\n\n\n\n```{r}\n# step 1: create wide data versions of the two tables\nbfi2_wide <- bfi2 |> pivot_wider(id_cols = c(agent_id, instrument_id), \n                           names_from = c(stimulus_id, iteration), \n                           names_glue = \"{stimulus_id}_{.value}_i{iteration}\",\n                           values_from = c(trial_index,\n                                           stimulus_type,\n                                           stimulus_description, \n                                           response_option_index, \n                                           response_description, \n                                           response_numeric, \n                                           response_time, \n                                           response_validation_time))\n\npsqi_wide <- psqi |> pivot_wider(id_cols = c(agent_id, instrument_id), \n                           names_from = c(stimulus_id, iteration), \n                           names_glue = \"{stimulus_id}_{.value}_i{iteration}\",\n                          values_from = c(trial_index,\n                                           stimulus_type,\n                                           stimulus_description, \n                                           response_option_index, \n                                           response_description, \n                                           response_numeric, \n                                           response_time, \n                                           response_validation_time))\n\n# step 2: create a table that combines data from the two questionnaires\nD_tidy <- rbind(bfi2, psqi)\n\nD_wide <- full_join(bfi2_wide, psqi_wide, by = \"agent_id\")\n\n\n# step 3: save the generated tables as csv files\nwrite.csv(bfi2_wide, file = 'data/x_bfi2_wide.csv')\nwrite.csv(psqi_wide, file = 'data/psqi_wide.csv')\nwrite.csv(D_tidy, file = 'data/D_tidy.csv')\nwrite.csv(D_wide, file = 'data/D_wide.csv')\n\n```\n\n```{r}\n#| echo: false\n\n# Create a data frame for the table\ntable_data <- data.frame(\n  dataset = c(\"bfi2\", \"psqi\", \"D_tidy (combined)\", \"\", \"bfi2_wide\", \"psqi_wide\", \"D_wide (combined)\"),\n  rows = c(nrow(bfi2), nrow(psqi), nrow(D_tidy), NA, nrow(bfi2_wide), nrow(psqi_wide), nrow(D_wide)),\n  columns = c(ncol(bfi2), ncol(psqi), ncol(D_tidy), NA, ncol(bfi2_wide), ncol(psqi_wide), ncol(D_wide)),\n  rows_x_cols = c(prod(dim(bfi2)), prod(dim(psqi)), prod(dim(D_tidy)), NA, prod(dim(bfi2_wide)), prod(dim(psqi_wide)), prod(dim(D_wide))),\n  NAs = c(sum(is.na(bfi2)), sum(is.na(psqi)), sum(is.na(D_tidy)), NA, sum(is.na(bfi2_wide)), sum(is.na(psqi_wide)), sum(is.na(D_wide))),\n  csv_size = c(\"31.5 KB\", \"27.5 KB\", \"66.6 KB\", \"\", \"59.6 KB\", \"36.2 KB\", \"109.1 KB\")\n)\n\nknitr::kable(table_data, col.names = c(\"dataset\", \"rows\", \"columns\", \"rows x cols\", \"NAs\", \"csv size\"),\n             caption = \"Dimensions and NA counts for each dataset, separately and combined, under the tidy and the wide tabular formats.\")\n```\n\n\n\n\nThere are several important points to note in the table above. The tidy data tables all have the same small number of columns; their number of rows will vary depending on the amount of data collected. Conversely, their wide-formatted counterparts have a number of rows and columns that both depend on the specific dataset and study design (e.g., more repetitions of the same questions would lead to more columns). Thus the shape of the tables when they are wide is less predictable. Furthermore, because columns represent the attributes of an observation, the wide format is much more difficult to process. For example, there are 978 columns in the wide version of the bfi2 data but only 12 in its tidy version. When looking at the number of missing values it is clear to see that in some cases (when data is sparse), the number of missing values increases substantially when transforming the data from tidy to wide (for bfi2, that number increased from 15 to 503). Another important observation is that when combining tidy questionnaire tables, the resulting table is easily predictable: the numbers of rows and the number of NAs are simply added, while the number (and meaning) of the columns remain the same. In contrast, when combining wide data tables, the resulting table is unpredictable without knowledge about the content of the data. Note also the large increase in NAs for this combined table (5121) compared to the combined tidy data (115).\n \nWe also wanted to assess whether these data formats affect the size of the data. One simple but somewhat naive way of assessing size is to count the number of cells in each table. While this may in principle serve as a proxy, it is not that straightforward because the data in each cell may require more or less memory space depending for instance on how it is encoded (e.g., a boolean vs a string). The strategy we chose here was to save the various data tables as csv files and assess the size of those files. As can be seen in the table, the wide formats in our example are systematically larger than their tidy counterparts.    \n\n\n\n\n## Scoring questionnaires\n\nThe next step will be to score each of the questionnaires, using the tidy and wide data formats and compare their advantages and disadvantages. In addition to computing those scores we will also compute the median response time to answer the corresponding questions. While this is not classically done, the idea of including it here is to assess how computing additional metrics on more than one response attribute would affect the complexity of the code.\n\n\n### BFI-2\n\n#### The wide data format\n\nWe'll start with the wide data format as this is the most common and the \"approach\" to scoring such data appears at least conceptually the most straightforward: because the data is already organized in an one-row-per-person format, scoring a questionnaire simply implies doing specific operations on a subset of the columns of that table.\n\n\nLet's start with a simple example: computing the *anxiety* score from the bfi2 data. According to the [documentation](https://www.colby.edu/academics/departments-and-programs/psychology/research-opportunities/personality-lab/the-bfi-2/), this requires using the responses from the items  Anxiety: 4R, 19, 34, 49R (where R indicates items that need to be reverse coded).\n\nSo our first challenge is to figure out how to find the responses to those times in our dataset. \n\n\n```{r}\n# custom function to convert response option index into the response score as defined in documentation\ncompute_agreement_rate_vector <- function(x, level_count = 7, reverse = FALSE){\n  rate <- (x-1)/(level_count-1)  \n  if (reverse){\n    rate <- 1-rate\n  }\n  rate\n}\n\n\n\n# custom function to compute the anxiety score\ncompute_anxiety_score <- function(df, iteration){\n  # - Anxiety: 4R, 19, 34, 49R\n  iteration_text <- paste0('_i', iteration)\n (compute_agreement_rate_vector(df[[paste0('bfi-2_q_4_response_option_index', iteration_text)]], reverse = TRUE) +\n  compute_agreement_rate_vector(df[[paste0('bfi-2_q_19_response_option_index', iteration_text)]], reverse = FALSE) +\n  compute_agreement_rate_vector(df[[paste0('bfi-2_q_34_response_option_index', iteration_text)]], reverse = FALSE) +\n  compute_agreement_rate_vector(df[[paste0('bfi-2_q_49_response_option_index', iteration_text)]], reverse = TRUE)) / 4\n}\n\n# computing the anxiety score and adding as a new column to the data\nD_wide$anxiety_score_i1 <- compute_anxiety_score(D_wide, iteration = 1)\nD_wide$anxiety_score_i2 <- compute_anxiety_score(D_wide, iteration = 2)\n\n\n# we can do something similar to compute the average response times\ncompute_anxiety_response_times <- function(df, iteration){\n  iteration_text <- paste0('_i', iteration)\n  (df[[paste0('bfi-2_q_4_response_time', iteration_text)]] +\n  df[[paste0('bfi-2_q_19_response_time', iteration_text)]] +\n  df[[paste0('bfi-2_q_34_response_time', iteration_text)]] +\n  df[[paste0('bfi-2_q_49_response_time', iteration_text)]]) / 4\n}\n\nD_wide$anxiety_response_times_i1 <- compute_anxiety_response_times(D_wide, iteration = 1)\nD_wide$anxiety_response_times_i2 <- compute_anxiety_response_times(D_wide, iteration = 2)\n\n```\n\n```{r}\nD_wide[c('agent_id', 'anxiety_score_i1', 'anxiety_score_i2', 'anxiety_response_times_i1', 'anxiety_response_times_i2')]\n```\n\n\nThere are several points we want to highlight about the code above. Firstly, this type of code tends to be quite verbose. We wrote functions here to aim to make that code compact; in practice it is rather common to not see any such functions but instead see long assignment statements. \n\nSecondly, the code above is strongly tied, not only to information about the questionnaire (e.g., which items to pick)--which is unavoidable--, it is also strongly tied to the specific way in which the column names have been arbitrarily constructed. If for some reason we change how column names are constructed, we could have to replace all of the code above. Furthermore, if the study had not involved repetitions, the naming would have been different and thus we would have again to change the code. \n\nThird, as in our example there are (up to) 2 repetitions of this questionnaire, we have to manually run the scoring code on each value of those iterations. Again, if there were a different number of iterations or different  intentions to group data (e.g., completing surveys in morning vs evening), we would again have to change the code above.\n\nFinally, when computing multiple aggregates on a particular response (in our example, how long they took to respond to those questions), we can see that it requires pretty much writing an independent chunk of code (the code for the anxiety response time and the code for anxiety scores are run independently from each other). This means that there are redundancies and the potential for mistakes. For example, the selection of items is the same in both cases (i.e., 4R, 19, 34, 49R), but this selection is specified in two different locations (both as part of the column names to be selected). As these are entered manually, and because for a given study there could potentially be a large number of such duplicated lists (e.g., there are 20 scores that one can compute out of this bfi2 questionnaire) which makes it hard to not make mistakes and to check that no mistakes were made. The above code takes about 25 lines to compute two metrics for one dimension; if we extrapolate, scoring the bfi2 questionnaire in this way would require 500 lines of code. \n\n\n> The names of the aggregated values need to be specified by the data analyst. For example, here we chose \"anxiety_score_i1\". This is again an arbitrary choice (we could have picked instead \"score_bfi_anx_1\", \"anxiety_r1_bfi2\", or something else). This custom naming of the outputs requires extra work, is specific to the dataset (if there were more repetitions, we would need additional assignment statements); it will also cause the subsequent code to be tailor made to those specific column names.\n\n\nIt is of course possible to develop more custom code (i.e., more functions) to make the data analysis code more compact, less redundant and less error prone. But that code would require extra work, it would likely be highly specific to the way the column names were constructed for this particular dataset, and in practice, this does not seem to be what data analysts do. \n\n\n#### The tidy data format\n\nWe will now do the same type of analysis starting with the tidy data format.\n\n\n\n```{r}\n\nscore_bfi2_anxiety <- function(df){\n\n    df |> \n    # \"select\" the relevant items for this scale\n    filter(stimulus_id %in% paste0(\"bfi-2_q_\", c(4, 19, 34, 49))) |> \n    # recode responses into 0-1 \n    mutate(response_score = ifelse(stimulus_id %in% paste0(\"bfi-2_q_\", c(4, 49)), \n                                   compute_agreement_rate_vector(response_option_index, reverse = TRUE), # reverse score for selected items \n                                   compute_agreement_rate_vector(response_option_index, reverse = FALSE))) |> \n    # compute score for this scale\n    summarize(\n      dimension = \"bfi2_extraversion\",\n      score = mean(response_score), \n      response_time_mean = mean(response_time),\n      .groups = \"drop\")\n  \n}\n\n\n# compute the scores for our dataset\nbfi2_anxiety <- D_tidy |> \n  group_by(agent_id, iteration) |> \n  score_bfi2_anxiety()\n\nknitr::kable(bfi2_anxiety)\n```\n\nThere are several points worth noting about the code above. Firstly, the code in `score_bfi2_anxiety()` only contains information about the IDs of the items that need to be used and how they are to be used. It does not contain any information related to the specifics of the study or data analysis intention. For instance, there is no notion of \"repetition\" in this code. Second, the selection of relevant items is done only once with the filter statement; this makes the code more compact and less error prone.  Thirdly, the way that aggregates are computed on the data--which is done via the `summarize()`--makes it very easy to add additional metrics. For instance, if one wanted to also compute the minimum, maximum of and standard deviation of the response times, it would only require one additional statement per metric within the summarise function (e.g., `response_time_min = min(response_time)`; this is in stark contrast with how we analyzed the wide data.\n\nForth, if we look at how those functions are being applied to the data, we can see that by using the `group_by()` function (which is part of the dplyr package, included in the tidyverse) we can apply the scoring functions for any type of subset of our data. Here we specify that we want to have separate scoring for each agent and for each iteration. We don't need to know or specify in advance how many iterations are in the dataset. The number of iterations does not impact the amount of code one needs to write. This code is also easy to update in the future; if there was a \"time_of_day\" column, that column could be used to compute different scores for whatever levels that variable has by simply changing the contents of that group_by() function. Importantly, this coding approach cleanly separates the scoring function which is tied only to the questionnaire used from the specific study design and data analysis strategies (which in our example is embedded in the group_by() function call).\n\n\nIt is also important to note that the output of the scoring \"anxiety\" following this approach is again a tidy table where no extra effort was required to name things. The shape of this table will depend on the specific analysis that was computed (e.g., if there are more iterations, there will be more rows), but the columns of that table will reflect the various metrics computed in the summary call.\n\nOf course at some point one may want to display the table as a one-row-per-person table; this can be done quite easily. \n\n\n#### Scoring the bfi2 questionnaire as a whole\n\nAs stated earlier we won't use the strategy we employed for the wide data to score all of the dimensions as this would take us quite some time to do and would not be very interesting. But doing this exercise would certainly allow the reader to experience how painful that could be.\n\nHere we will only use the tidy data as a starting point. We will abstract the code above a bit more to show how compact questionnaire data analysis may be.\n\n\n\n```{r}\n# function to \"recode\" response values\ncompute_agreement_rate <- function(df, col = \"response_option_index\", level_count = 7, reverse = FALSE){\n  rate <- (df[[col]] - 1) / (level_count - 1)\n  if (reverse){\n    rate <- 1 - rate\n  }\n  rate\n}\n\n\n\n# function takes as input a data frame (df) and a list containing the parameters of a specific scale and outputs the resulting scores and response times\n# recode and aggregate\nscore_questionnaire <- function(df, scoring_params){\n  \n  # if reverse_ids is not defined, copy stimulus_ids\n  if (all(is.na(scoring_params$reverse_ids))){\n    scoring_params$reverse_ids <- \"__none__\"\n  }\n  \n  df |> \n    filter(stimulus_id %in% scoring_params$stimulus_ids) |> \n    mutate(response_score = ifelse(stimulus_id %in% scoring_params$reverse_ids, \n                                   scoring_params$recode_func(pick(everything()), reverse = TRUE), \n                                   scoring_params$recode_func(pick(everything()), reverse = FALSE))) |> \n    summarize(dimension = scoring_params$dimension,\n              score = mean(response_score, na.rm = TRUE), \n              response_time = mean(response_time, na.rm = TRUE), \n              n = n(),\n              na_n = sum(is.na(response_time)),\n              .groups = \"drop\"\n              ) \n}\n\n\n```\n \nThe code above is quite generic and applies to the common case where response option indices are converted to numbers using a particular set of rules and then aggregated. Because this code is generic and could apply to a wide range of questionnaires, it could be part of a package and reused broadly, preventing the need to write custom code.\n\nWe wrote the code in a way that the `score_questionnaire()` takes as input the questionnaire data and a list of parameters that specify how to score a particular dimension. This type of code that separates the specifics of a score (tied to a particular instrument) from the mechanics of computing the score is preferable over hard coding the specifics in the analysis code directly (as we did earlier) as it makes it easier to review if the specification is correct or not. \n\n\nTo compute a specific score, we will then need to do the following:\n\n\n```{r}\n# we can now encode the scoring rules for the questionnaire in a compact way:\nbfi2_extraversion <- list(\n  dimension = \"bfi2_extraversion\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(11, 16, 26, 31, 36, 51))\n)\n\n\n\n# and use the generic code to compute the results for that dimension:\nD_tidy |> \n  group_by(agent_id, iteration) |> \n  score_questionnaire(bfi2_extraversion) |> \n  knitr::kable()\n\n\n```\n\nTo compute all of the 20 scores from the bfi2 questionnaires, we first need to specify the parameters for each score. This can be done all in one, easy to review, place:\n\n```{r}\n# Storing all the scoring rules for the bfi-2 questionnaire in lists:\n\n## Extraversion: 1, 6, 11R, 16R, 21, 26R, 31R, 36R, 41, 46, 51R, 56\nbfi2_extraversion <- list(\n  dimension = \"bfi2_extraversion\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(11, 16, 26, 31, 36, 51))\n)\n\n## Agreeableness: 2, 7, 12R, 17R, 22R, 27, 32, 37R, 42R, 47R, 52, 57\nbfi2_agreeableness <- list(\n  dimension = \"bfi2_agreeableness\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(2, 7, 12, 17, 22, 27, 32, 37, 42, 47, 52, 57)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(12, 17, 22, 37, 42, 47))\n)\n\n## Conscientiousness: 3R, 8R, 13, 18, 23R, 28R, 33, 38, 43, 48R, 53, 58R\nbfi2_conscientiousness <- list(\n  dimension = \"bfi2_conscientiousness\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(3, 8, 13, 18, 23, 28, 33, 38, 43, 48, 53, 58)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(3, 8, 23, 28, 48, 58))\n)\n\n## Negative Emotionality: 4R, 9R, 14, 19, 24R, 29R, 34, 39, 44R, 49R, 54, 59\nbfi2_negative <- list(\n  dimension = \"bfi2_negative\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(4, 9, 14, 19, 24, 29, 34, 39, 44, 49, 54, 59)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(4, 9, 24, 29, 44, 49))\n)\n\n## Open-Mindedness: 5R, 10, 15, 20, 25R, 30R, 35, 40, 45R, 50R, 55R, 60\nbfi2_open <- list(\n  dimension = \"bfi2_open\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(5, 25, 30, 45, 50, 55))\n)\n\n## Sociability: 1, 16R, 31R, 46\nbfi2_sociability <- list(\n  dimension = \"bfi2_sociability\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(1, 16, 31, 46)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(16, 31))\n)\n\n## Assertiveness: 6, 21, 36R, 51R\nbfi2_assertiveness <- list(\n  dimension = \"bfi2_assertiveness\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(6, 21, 36, 51)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(36, 51))\n)\n\n## Energy Level: 11R, 26R, 41, 56\nbfi2_energy <- list(\n  dimension = \"bfi2_energy\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(11, 26, 41, 56)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(11, 26))\n)\n\n## Compassion: 2, 17R, 32, 47R\nbfi2_compassion <- list(\n  dimension = \"bfi2_compassion\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(2, 17, 32, 47)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(17, 47))\n)\n\n## Respectfulness: 7, 22R, 37R, 52\nbfi2_respectfulness <- list(\n  dimension = \"bfi2_respectfulness\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(7, 22, 37, 52)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(22, 37))\n)\n\n## Trust: 12R, 27, 42R, 57\nbfi2_trust <- list(\n  dimension = \"bfi2_trust\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(12, 27, 42, 57)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(27, 57))\n)\n\n## Organization: 3R, 18, 33, 48R\nbfi2_organization <- list(\n  dimension = \"bfi2_organization\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(3, 18, 33, 48)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(3, 48))\n)\n\n## Productiveness: 8R, 23R, 38, 53\nbfi2_productiveness <- list(\n  dimension = \"bfi2_productiveness\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(8, 23, 38, 53)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(8, 23))\n)\n\n## Responsibility: 13, 28R, 43, 58R\nbfi2_responsibility <- list(\n  dimension = \"bfi2_responsibility\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(13, 28, 43, 58)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(28, 58))\n)\n\n## Anxiety: 4R, 19, 34, 49R\nbfi2_anxiety <- list(\n  dimension = \"bfi2_anxiety\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(4, 19, 34, 49)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(4, 49))\n)\n\n## Depression: 9R, 24R, 39, 54\nbfi2_depression <- list(\n  dimension = \"bfi2_depression\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(9, 24, 39, 54)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(9, 24))\n)\n\n## Emotional Volatility: 14, 29R, 44R, 59\nbfi2_volatility <- list(\n  dimension = \"bfi2_volatility\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(14, 29, 44, 59)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(29, 44))\n)\n\n## Intellectual Curiosity: 10, 25R, 40, 55R\nbfi2_curiosity <- list(\n  dimension = \"bfi2_curiosity\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(10, 25, 40, 55)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(25, 55))\n)\n\n## Aesthetic Sensitivity: 5R, 20, 35, 50R\nbfi2_aesthetic <- list(\n  dimension = \"bfi2_aesthetic\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(5, 20, 35, 50)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(5, 50))\n)\n\n## Creative Imagination: 15, 30R, 45R, 60\nbfi2_imagination <- list(\n  dimension = \"bfi2_imagination\",\n  recode_func = compute_agreement_rate,\n  stimulus_ids = paste0(\"bfi-2_q_\", c(15, 30, 45, 60)),\n  reverse_ids = paste0(\"bfi-2_q_\",  c(30, 45))\n)\n\n```\n\n\nNote that the above is a sort of documentation of how to score the bfi2 questionnaire; this content should be an integral part of the questionnaire (and questionnaire data collection system) itself rather than being manually entered as we did here.\n\nOnce we have defined the list of scores we want to compute on our data, we can create a list of those parameter lists: \n\n\n```{r}\n## We can group all of those scale parameter lists into an instrument specific list\nbfi2_params <- list(\n  # 5 domain scales:\n  bfi2_extraversion,\n  bfi2_agreeableness,\n  bfi2_conscientiousness,\n  bfi2_negative,\n  bfi2_open,\n  # 15 facets:\n  bfi2_sociability,\n  bfi2_assertiveness,\n  bfi2_energy,\n  bfi2_compassion,\n  bfi2_respectfulness,\n  bfi2_trust,\n  bfi2_organization,\n  bfi2_productiveness, \n  bfi2_responsibility,\n  bfi2_anxiety,\n  bfi2_depression,\n  bfi2_volatility,\n  bfi2_curiosity,\n  bfi2_aesthetic,\n  bfi2_imagination)\n\n```\n\n\nThe next step is then to execute the scoring code on each of them:\n\n\n```{r}\n# we use purrr instead of for loops\n# we also first create a wrapper to simplify code\nf <- function(df, param_list){\n  df |> \n      group_by(agent_id, iteration) |> \n      score_questionnaire(param_list)\n}\n\nbfi2_scores <- map_dfr(bfi2_params, ~ f(D_tidy, .x))\n```\n\n\nThus if we exclude the generic code and the specification of how to score the bfi2 questionnaire, the code to score the questionnaire only takes a handful of lines of code, which are the same irrespective of the number of scores to extract from the questionnaire or from the number of iterations that participants completed.\n\n\nSome people might want at this stage to have a table showing for each person their score on the various dimensions of the questionnaire. We could simply use pivot_wider() here to create a one-person-per-row table. However, it is unlikely that we would want to display all of the data in bfi2_scores. As an example, we will only display the scores (i.e., ignoring response_time, n and na_n) and average the scores across repetitions when there are multiple. \n\n```{r}\nbfi2_scores_wide <- bfi2_scores |> \n  # averaging scores across repetitions for each dimension\n  group_by(agent_id, dimension) |> \n  summarize(score = mean(score, na.rm=TRUE), .groups = \"drop\") |> \n  # reshaping the table\n  pivot_wider(id_cols = agent_id, names_from = dimension, values_from = score)\n\n```\n```{r}\nknitr::kable(bfi2_scores_wide)\n```\n\n\n\n\n### PSQI\n\nThe PSQI questionnaire is more challenging to score because it involves a larger variety of response formats and because the scoring procedure is a bit more involved.\n\nAlso for brevity we will only focus only on computing the score for \"Component 2: Sleep latency\" as it involves multiple steps.\n\n\n#### The wide data format\n\n```{r}\n# question 2: convert duration ranges into integer 0-3\n# question 5: convert choice into integer 0-3\n# sum previous two scores\n# convert the sum into integer 0 -3\n\n\n# score question 2:\nvalidate_psqi_question_2_input <- function(x){\n  if (!is.numeric(x)) {\n    stop(\"Input must be numeric\")\n  } else if (any(x < 0, na.rm = TRUE)){\n    stop(\"Input must be larger than 0\")\n  }\n  return(x)\n}\n\n# validate_psqi_question_2_input(c(1, 1, 2, NA))\n\n\n\nscore_psqi_question_2 <- function(x){\n  validate_psqi_question_2_input(x)\n  as.numeric(cut(x, breaks = c(0,15, 30, 60, 24*60))) - 1\n}\n\n\n\n\n# score question 5:\nvalidate_psqi_question_5_input <- function(x){\n  \n  q5_levels = c(\"not during the past month\", \"less than once a week\", \"once or twice a week\", \"three or more times a week\")\n  \n  if (is.factor(x)) { # if x is encoded as a factor variable\n    if (! all(levels(x) == q5_levels)){\n      stop(paste0(\"Input does not have the required levels: \\nInput levels: \", levels(x), \"\\nExpected levels: \", q5_levels))\n    }\n  } else if (!is.character(x)){\n    stop(\"Input must be either factor or string\")\n  } else {\n    # check inputs are \n    for (element in x){\n      if (is.na(element)) next\n      if (!element %in% q5_levels){\n        stop(paste0(\"Input contains unexpected values: \", element) )\n      }\n    }\n  }\n  return(x)\n}\n\n\n\nscore_psqi_question_5 <- function(x){\n  validate_psqi_question_5_input(x)\n  as.numeric(\n    factor(x, levels = c(\"not during the past month\", \"less than once a week\", \"once or twice a week\", \"three or more times a week\"))\n  )-1\n}\n\n\n\n\n\n# combine the subcomponent scores\nscore_sleep_latency_components <- function(x,y){\n  as.numeric(\n    cut(x + y, breaks = c(-1, 0, 2, 4, 6))\n  )-1\n}\n\n# wrapper to do all the previous steps in one function call\nscore_sleep_latency <- function(q2,q5){\n  x <- score_psqi_question_2(q2)\n  y <- score_psqi_question_5(q5)\n  score_sleep_latency_components(x,y)\n}\n```\n\nThe code above shows that one can write simple functions to process each question separately, a function to aggregate those results and a wrapper function to keep the data analysis code cleaner.  It is important to note here that this code expects very specific input values: in the first case a number of minutes (i.e., a positive number between 0 and 1440), in the second, one out of 4 possible response categories. In the above code we show how the data analysis code can make sure that the input is as expected (as opposed to relying on the data being correctly formatted). \n\nHaving created those functions, we can now analyze our specific dataset:\n\n```{r}\n# use the above code to compute the psqi sleep latency score for each iteration and append to data\nD_wide <- D_wide |> \n  mutate(psqi_latency_score_i1 = score_sleep_latency(\n                                      psqi_q_2_response_numeric_i1, \n                                      `frequency_trouble_sleep_because;psqi-past_q_6_response_description_i1`\n                                      ),\n         psqi_latency_score_i2 = score_sleep_latency(\n                                      psqi_q_2_response_numeric_i2, \n                                      `frequency_trouble_sleep_because;psqi-past_q_6_response_description_i2`\n                                      )\n         ) \n\n\n\n```\n\n\nThe above code is rather compact thanks to the use of functions. However, as in with the bfi2_wide example, we end up having to write code that is specific to our study: we need to compute the scores separately for each iteration, which leads to duplicated code and the potential to make mistakes (forgetting to change the i1 to i2 when copy-pasting code). \n\nThe second observation: we add new columns to the main table; we are now mixing in the table things that are data (responses to questions) and things that we compute using that data (the psqi sleep latency score). We could of course save the resulting columns in a separate table.\n\n```{r}\nD_wide |> \n  select(agent_id, psqi_latency_score_i1, psqi_latency_score_i2) |> \n  knitr::kable()\n\n```\n\n\n#### The tidy data format\n\nWe could use an approach similar to what we did for BFI-2: define a list of parameters to compute a specific score and a generic function to run the analysis of data. This would work for calculating the subscores, but then a second step would be required to compute the aggregate score from those two subscores. \n\nThe alternative is to create a function that takes as input a data frame and returns the scores\n\n\n\n```{r}\nscore_sleep_latency_components_df <- function(x){\n\n  if (length(x) != 2){\n    stop(\"Data does not have the expected number of items\")\n  } else {\n    score_sleep_latency_components(x[1], x[2])\n  }\n  \n}\n\n\n\nscore_psqi_latency <- function(df){\n  \n  # because rowwise will override any existing groups, we need to save and restore them when needed\n  group_vars <- dplyr::group_vars(df)\n  \n  df |> \n    filter(stimulus_id %in% c(\"psqi_q_2\", \"frequency_trouble_sleep_because;psqi-past_q_6\")) |> \n    # process each question separately\n    rowwise() |> \n    mutate(score_tmp = ifelse(stimulus_id==\"psqi_q_2\", \n                          score_psqi_question_2(response_numeric), \n                          NA)) |> \n    mutate(score_tmp = ifelse(stimulus_id==\"frequency_trouble_sleep_because;psqi-past_q_6\",\n                          score_psqi_question_5(response_description), \n                          score_tmp)) |> \n    ungroup() |> \n    group_by(across(all_of(group_vars))) |> \n    \n    # aggregate scores across all selected responses\n    summarize(dimension = \"psqi_latency\", \n              score = score_sleep_latency_components_df(score_tmp), \n              response_time = mean(response_time, na.rm = TRUE), \n              n = n(),\n              na_n = sum(is.na(response_time)),\n              .groups = \"drop\"\n              ) \n  \n}\n```\n\n\n\n```{r}\nD_tidy |> \n  group_by(agent_id, iteration) |> \n  score_psqi_latency()\n\n```\n\n\nThe code in this case is quite a bit more complex; the main advantages are however that a) we can compute more metrics on the selected items without much effort (e.g., response_time) compared to the strategy we used on the wide data format and b) we can have studies that involve any number of iterations (or other types of grouping variables) and reuse the exact same code; in contrast, the code used on the wide data format is strongly tied to the specifics of the study, be it through the study parameters encoded in the column names or the number of steps required in the analysis.\n\n\n## Conclusion\n\nThis notebook presents a more realistic, although still simplified, example of the analysis of questionnaire data using the wide and tidy data formats respectively. Overall, the tidy data format seems preferable for several reasons. However, we also note that in some cases handling the tidy data format may require code that is more complex than the wide data format. \n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"tidy_questionnaire_data_demo.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.39","title":"Tidy questionnaire data: demo"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["pdf"]}